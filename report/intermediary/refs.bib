@article{Karthika2022,
  author   = {Karthika, R.
              and Parameswaran, Latha},
  title    = {A Novel Convolutional Neural Network Based Architecture for Object Detection and Recognition with an Application to Traffic Sign Recognition from Road Scenes},
  journal  = {Pattern Recognition and Image Analysis},
  year     = {2022},
  month    = {Jun},
  day      = {01},
  volume   = {32},
  number   = {2},
  pages    = {351--362},
  abstract = {Object detection and recognition is a significant activity in computer vision applications. Advanced driver assistance systems (ADAS) uses computer vision predominantly as its tool. For improving the performance of ADAS, traffic sign is one of the important object that needs to be detected and recognized to assist the drivers for safe driving. Under real time conditions, this befits extremely challenging due to varying illumination, resolution of images, external weather conditions, position of sign board and occlusions. This article proposes an efficient algorithm that can detect, and classify (recognize) the traffic signs. This traffic sign processing has been done in two phases: sign detection and sign recognition through classification. In the first phase, the traffic signs are detected using YOLOv3 architecture by generating seven classes based on shape, color and background. In phase 2, traffic sign classification has been done using the newly proposed architecture based on convolutional neural networks, using the output generated from the first phase. The German Traffic Sign Detection Benchmark (GTSDB) and German Traffic Sign Recognition Benchmark (GTSRB) datasets have been used for experimentation. The proposed method gives a mean average precision of 89.56{\%} for traffic sign detection with an accuracy of 86.6{\%} for traffic sign recognition. This shows the efficacy of the proposed architecture.},
  issn     = {1555-6212},
  doi      = {10.1134/S1054661822020110},
  url      = {https://doi.org/10.1134/S1054661822020110}
}

@inproceedings{4370763,
  author    = {Malik, Rabia and Khurshid, Javaid and Ahmad, Sana Nazir},
  booktitle = {2007 International Conference on Machine Learning and Cybernetics},
  title     = {Road Sign Detection and Recognition using Colour Segmentation, Shape Analysis and Template Matching},
  year      = {2007},
  volume    = {6},
  number    = {},
  pages     = {3556-3560},
  doi       = {10.1109/ICMLC.2007.4370763}
}

@article{metastudy2019,
  title     = {Vision-Based Traffic Sign Detection and Recognition Systems: Current Trends and Challenges},
  volume    = {19},
  issn      = {1424-8220},
  url       = {http://dx.doi.org/10.3390/s19092093},
  doi       = {10.3390/s19092093},
  number    = {9},
  journal   = {Sensors},
  publisher = {MDPI AG},
  author    = {Wali, Safat B. and Abdullah, Majid A. and Hannan, Mahammad A. and Hussain, Aini and Samad, Salina A. and Ker, Pin J. and Mansor, Muhamad Bin},
  year      = {2019},
  month     = {May},
  pages     = {2093}
}

@inproceedings{4290244,
  author    = {Broggi, Alberto and Cerri, Pietro and Medici, Paolo and Porta, Pier Paolo and Ghisio, Guido},
  booktitle = {2007 IEEE Intelligent Vehicles Symposium},
  title     = {Real Time Road Signs Recognition},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {981-986},
  doi       = {10.1109/IVS.2007.4290244}
}

@article{8709983,
  author  = {Tabernik, Domen and Skočaj, Danijel},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  title   = {Deep Learning for Large-Scale Traffic-Sign Detection and Recognition},
  year    = {2020},
  volume  = {21},
  number  = {4},
  pages   = {1427-1440},
  doi     = {10.1109/TITS.2019.2913588}
}

@inproceedings{6196571,
  author    = {Hechri, Ahmed and Mtibaa, Abdellatif},
  booktitle = {2012 16th IEEE Mediterranean Electrotechnical Conference},
  title     = {Automatic detection and recognition of road sign for driver assistance system},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {888-891},
  doi       = {10.1109/MELCON.2012.6196571}
}

@inproceedings{Houben-IJCNN-2013,
  author    = {Sebastian Houben and Johannes Stallkamp and Jan Salmen and Marc Schlipsing and Christian Igel},
  booktitle = {International Joint Conference on Neural Networks},
  title     = {Detection of Traffic Signs in Real-World Images: The {G}erman {T}raffic {S}ign {D}etection {B}enchmark},
  number    = {1288},
  year      = {2013}
}

@inproceedings{Paszke_PyTorch_An_Imperative_2019,
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  editor    = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  pages     = {8024--8035},
  publisher = {Curran Associates, Inc.},
  title     = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
  url       = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
  year      = {2019}
}

@software{Jocher_YOLO_by_Ultralytics_2023,
  author  = {Jocher, Glenn and Chaurasia, Ayush and Qiu, Jing},
  license = {AGPL-3.0},
  month   = jan,
  title   = {{YOLO by Ultralytics}},
  url     = {https://github.com/ultralytics/ultralytics},
  version = {8.0.0},
  year    = {2023}
}

@article{svm_paper,
  author   = {Hechri, Ahmed and Mtibaa, Abdellatif},
  title    = {Two-stage traffic sign detection and recognition based on SVM and convolutional neural networks},
  journal  = {IET Image Processing},
  volume   = {14},
  number   = {5},
  pages    = {939-946},
  keywords = {feature extraction, driver information systems, road traffic, object detection, road safety, object recognition, support vector machines, convolutional neural nets, image classification, German traffic sign recognition benchmark datasets, recognition rate, stage traffic sign detection, convolutional neural network, advanced driver assistance systems, safety, road traffic scenes, real-time traffic sign detection, traffic situation, linear support vector machines, German traffic sign detection benchmark datasets},
  doi      = {https://doi.org/10.1049/iet-ipr.2019.0634},
  url      = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-ipr.2019.0634},
  eprint   = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/iet-ipr.2019.0634},
  abstract = {Nowadays, traffic sign recognition is the most important task of advanced driver assistance systems since it improves the safety and comfort of drivers. However, it remains a challenging task due to the complexity of road traffic scenes. In this study, a novel two-stage approach for real-time traffic sign detection and recognition in a real traffic situation was proposed. The first stage aims to detect and classify the detected traffic signs into circular and triangular shape using HOG features and linear support vector machines (SVMs). The main objective of the second stage is to recognise the traffic signs using a convolutional neural network into their subclasses. The performance of the whole process is tested on German traffic sign detection benchmark (GTSDB) and German traffic sign recognition benchmark (GTSRB) datasets. Experimental results show that the obtained detection and recognition rate is comparable with those reported in the literature with much less complexity. Furthermore, the average processing time demonstrates its suitability for real-time processing applications.},
  year     = {2020}
}

@misc{chollet2015keras,
  title        = {Keras},
  author       = {Chollet, Fran\c{c}ois and others},
  year         = {2015},
  howpublished = {\url{https://keras.io}}
}

@software{Abadi_TensorFlow_Large-scale_machine_2015,
  author  = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jozefowicz, Rafal and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mané, Dan and Schuster, Mike and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viégas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  doi     = {10.5281/zenodo.4724125},
  license = {Apache-2.0},
  month   = nov,
  title   = {{TensorFlow, Large-scale machine learning on heterogeneous systems}},
  year    = {2015}
}

@article{scikit-learn,
  title   = {Scikit-learn: Machine Learning in {P}ython},
  author  = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
             and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
             and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
             Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal = {Journal of Machine Learning Research},
  volume  = {12},
  pages   = {2825--2830},
  year    = {2011}
}

@misc{matlabsvm,
  title        = {Support Vector Machine (SVM) Explained},
  author       = {MatLab},
  howpublished = {\url{https://www.mathworks.com/discovery/support-vector-machine.html}}
}
